{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment:confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason:confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>681448150</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 5:24</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 11:35</td>\n",
       "      <td>5.703060e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>681448153</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 1:53</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 11:15</td>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>681448156</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 10:01</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 11:15</td>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>681448158</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 3:05</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 11:15</td>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>681448159</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 5:50</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 11:14</td>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "0  681448150    False   finalized                   3      2/25/15 5:24   \n",
       "1  681448153    False   finalized                   3      2/25/15 1:53   \n",
       "2  681448156    False   finalized                   3     2/25/15 10:01   \n",
       "3  681448158    False   finalized                   3      2/25/15 3:05   \n",
       "4  681448159    False   finalized                   3      2/25/15 5:50   \n",
       "\n",
       "  airline_sentiment  airline_sentiment:confidence negativereason  \\\n",
       "0           neutral                        1.0000            NaN   \n",
       "1          positive                        0.3486            NaN   \n",
       "2           neutral                        0.6837            NaN   \n",
       "3          negative                        1.0000     Bad Flight   \n",
       "4          negative                        1.0000     Can't Tell   \n",
       "\n",
       "   negativereason:confidence         airline airline_sentiment_gold  \\\n",
       "0                        NaN  Virgin America                    NaN   \n",
       "1                     0.0000  Virgin America                    NaN   \n",
       "2                        NaN  Virgin America                    NaN   \n",
       "3                     0.7033  Virgin America                    NaN   \n",
       "4                     1.0000  Virgin America                    NaN   \n",
       "\n",
       "         name negativereason_gold  retweet_count  \\\n",
       "0     cairdin                 NaN              0   \n",
       "1    jnardino                 NaN              0   \n",
       "2  yvonnalynn                 NaN              0   \n",
       "3    jnardino                 NaN              0   \n",
       "4    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "   tweet_created      tweet_id tweet_location               user_timezone  \n",
       "0  2/24/15 11:35  5.703060e+17            NaN  Eastern Time (US & Canada)  \n",
       "1  2/24/15 11:15  5.703010e+17            NaN  Pacific Time (US & Canada)  \n",
       "2  2/24/15 11:15  5.703010e+17      Lets Play  Central Time (US & Canada)  \n",
       "3  2/24/15 11:15  5.703010e+17            NaN  Pacific Time (US & Canada)  \n",
       "4  2/24/15 11:14  5.703010e+17            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df = pd.read_csv(\"Airline-Sentiment-2-w-AA.csv\", encoding=\"latin-1\")\n",
    "main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-633337079cd0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment:confidence</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>681448150</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>681448153</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>681448156</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>681448158</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>681448159</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>681679794</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3487</td>\n",
       "      <td>@AmericanAir thank you we got on a different f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>681679795</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>681679796</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@AmericanAir Please bring American Airlines to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>681679797</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>681679798</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6771</td>\n",
       "      <td>@AmericanAir we have 8 ppl so we need 2 know h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        _unit_id airline_sentiment  airline_sentiment:confidence  \\\n",
       "0      681448150           neutral                        1.0000   \n",
       "1      681448153          positive                        0.3486   \n",
       "2      681448156           neutral                        0.6837   \n",
       "3      681448158          negative                        1.0000   \n",
       "4      681448159          negative                        1.0000   \n",
       "...          ...               ...                           ...   \n",
       "14635  681679794          positive                        0.3487   \n",
       "14636  681679795          negative                        1.0000   \n",
       "14637  681679796           neutral                        1.0000   \n",
       "14638  681679797          negative                        1.0000   \n",
       "14639  681679798           neutral                        0.6771   \n",
       "\n",
       "                                                    text  \n",
       "0                    @VirginAmerica What @dhepburn said.  \n",
       "1      @VirginAmerica plus you've added commercials t...  \n",
       "2      @VirginAmerica I didn't today... Must mean I n...  \n",
       "3      @VirginAmerica it's really aggressive to blast...  \n",
       "4      @VirginAmerica and it's a really big bad thing...  \n",
       "...                                                  ...  \n",
       "14635  @AmericanAir thank you we got on a different f...  \n",
       "14636  @AmericanAir leaving over 20 minutes Late Flig...  \n",
       "14637  @AmericanAir Please bring American Airlines to...  \n",
       "14638  @AmericanAir you have my money, you change my ...  \n",
       "14639  @AmericanAir we have 8 ppl so we need 2 know h...  \n",
       "\n",
       "[14640 rows x 4 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = main_df[[\"_unit_id\", \"airline_sentiment\", \"airline_sentiment:confidence\", \"text\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment:confidence</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>681448150</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>681448153</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>681448156</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>681448158</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>681448159</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id airline_sentiment  airline_sentiment:confidence  \\\n",
       "0  681448150           neutral                        1.0000   \n",
       "1  681448153          positive                        0.3486   \n",
       "2  681448156           neutral                        0.6837   \n",
       "3  681448158          negative                        1.0000   \n",
       "4  681448159          negative                        1.0000   \n",
       "\n",
       "                                                text  \n",
       "0                @VirginAmerica What @dhepburn said.  \n",
       "1  @VirginAmerica plus you've added commercials t...  \n",
       "2  @VirginAmerica I didn't today... Must mean I n...  \n",
       "3  @VirginAmerica it's really aggressive to blast...  \n",
       "4  @VirginAmerica and it's a really big bad thing...  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8452/2129448384.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"text\"] = df[\"text\"].apply(remove_nametags)\n"
     ]
    }
   ],
   "source": [
    "def remove_nametags(sentence):\n",
    "    \"\"\"A simple function to remove name tags\"\"\"\n",
    "    clean_words = []\n",
    "    for word in sentence.split():\n",
    "        if \"@\" not in word:\n",
    "            clean_words.append(word)\n",
    "    return \" \".join(clean_words)\n",
    "\n",
    "df[\"text\"] = df[\"text\"].apply(remove_nametags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8452/1497160858.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"text\"] = df[\"text\"].apply(lambda x: re.sub(to_remove, \"\", x))\n"
     ]
    }
   ],
   "source": [
    "# Removing numbers\n",
    "import re\n",
    "to_remove = r\"[0-9]\"\n",
    "\n",
    "df[\"text\"] = df[\"text\"].apply(lambda x: re.sub(to_remove, \"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                               What said.\n",
       "1        plus you've added commercials to the experienc...\n",
       "2        I didn't today... Must mean I need to take ano...\n",
       "3        it's really aggressive to blast obnoxious \"ent...\n",
       "4                 and it's a really big bad thing about it\n",
       "                               ...                        \n",
       "14635    thank you we got on a different flight to Chic...\n",
       "14636    leaving over  minutes Late Flight. No warnings...\n",
       "14637        Please bring American Airlines to #BlackBerry\n",
       "14638    you have my money, you change my flight, and d...\n",
       "14639    we have  ppl so we need  know how many seats a...\n",
       "Name: text, Length: 14640, dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8452/2943594681.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"text\"] = df[\"text\"].apply(lambda x:\\\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "df[\"text\"] = df[\"text\"].apply(lambda x:\\\n",
    "                              x.translate(str.maketrans(\"\", \"\",string.punctuation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8452/1324128920.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"text\"] = df[\"text\"].str.lower()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment:confidence</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>681448150</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>what said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>681448153</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>plus youve added commercials to the experience...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>681448156</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>i didnt today must mean i need to take another...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>681448158</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>its really aggressive to blast obnoxious enter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>681448159</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>and its a really big bad thing about it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id airline_sentiment  airline_sentiment:confidence  \\\n",
       "0  681448150           neutral                        1.0000   \n",
       "1  681448153          positive                        0.3486   \n",
       "2  681448156           neutral                        0.6837   \n",
       "3  681448158          negative                        1.0000   \n",
       "4  681448159          negative                        1.0000   \n",
       "\n",
       "                                                text  \n",
       "0                                          what said  \n",
       "1  plus youve added commercials to the experience...  \n",
       "2  i didnt today must mean i need to take another...  \n",
       "3  its really aggressive to blast obnoxious enter...  \n",
       "4            and its a really big bad thing about it  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"] = df[\"text\"].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                             what said\n",
       "1     plus youve added commercials to the experience...\n",
       "2     i didnt today must mean i need to take another...\n",
       "3     its really aggressive to blast obnoxious enter...\n",
       "4               and its a really big bad thing about it\n",
       "5     seriously would pay  a flight for seats that d...\n",
       "6     yes nearly every time i fly vx this ûïear wor...\n",
       "7     really missed a prime opportunity for men with...\n",
       "8                          well i didntûbut now i do d\n",
       "9     it was amazing and arrived an hour early youre...\n",
       "10    did you know that suicide is the second leadin...\n",
       "11    i lt pretty graphics so much better than minim...\n",
       "12    this is such a great deal already thinking abo...\n",
       "13    im flying your fabulous seductive skies again ...\n",
       "14                                               thanks\n",
       "15                         sfopdx schedule is still mia\n",
       "16    so excited for my first cross country flight l...\n",
       "17    i flew from nyc to sfo last week and couldnt f...\n",
       "18                             i ü flying ÷¼üùô\n",
       "19    you know what would be amazingly awesome bosfl...\n",
       "20    why are your first fares in may over three tim...\n",
       "21                 i love this graphic httptcoutgrrwaaa\n",
       "22    i love the hipster innovation you are a feel g...\n",
       "23    will you be making bosgtlas non stop permanent...\n",
       "24    you guys messed up my seating i reserved seati...\n",
       "25    status match program i applied and its been th...\n",
       "26    what happened  ur vegan food options at least ...\n",
       "27    do you miss me dont worry well be together ver...\n",
       "28    amazing to me that we cant get any cold air fr...\n",
       "29    lax to ewr  middle seat on a red eye such a no...\n",
       "30    hi i just bked a cool birthday trip with you b...\n",
       "31    are the hours of operation for the club at sfo...\n",
       "32    help left expensive headphones on flight  iad ...\n",
       "33    awaiting my return phone call just would prefe...\n",
       "34    this is great news america could start flights...\n",
       "35    nice rt vibe with the moodlight from takeoff t...\n",
       "36    moodlighting is the only way to fly best exper...\n",
       "37         done and done best airline around hands down\n",
       "38                  when can i book my flight to hawaii\n",
       "39    your chat support is not working on your site ...\n",
       "40    view of downtown los angeles the hollywood sig...\n",
       "41    hey first time flyer next week  excited but im...\n",
       "42    plz help me win my bid upgrade for my flight  ...\n",
       "43    i have an unused ticket but moved to a new cit...\n",
       "44    are flights leaving dallas for seattle on time...\n",
       "45            im elevategold for a good reason you rock\n",
       "46               dream httptcooadrfaoq httptcolwwdackhx\n",
       "47                           wow this just blew my mind\n",
       "48    after last night tribute soundofmusic oscars i...\n",
       "49                                all were entertaining\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8452/727677261.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"text\"] = df[\"text\"].apply(remove_emojis)\n"
     ]
    }
   ],
   "source": [
    "def remove_emojis(data):\n",
    "    \"\"\"A simple function to remove all emojis\"\"\"\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"\n",
    "                           u\"\\U00002500-\\U00002BEF\"\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           u\"\\U0001f926-\\U0001f937\"\n",
    "                           u\"\\U00010000-\\U0010ffff\"\n",
    "                           u\"\\u2640-\\u2642\" \n",
    "                           u\"\\u2600-\\u2B55\"\n",
    "                           u\"\\u200d\"\n",
    "                           u\"\\u23cf\"\n",
    "                           u\"\\u23e9\"\n",
    "                           u\"\\u231a\"\n",
    "                           u\"\\ufe0f\"\n",
    "                           u\"\\u3030\"\n",
    "                           \"]+\", re.UNICODE)\n",
    "    return re.sub(emoji_pattern, \"\", data)\n",
    "\n",
    "df[\"text\"] = df[\"text\"].apply(remove_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                             what said\n",
       "1     plus youve added commercials to the experience...\n",
       "2     i didnt today must mean i need to take another...\n",
       "3     its really aggressive to blast obnoxious enter...\n",
       "4               and its a really big bad thing about it\n",
       "5     seriously would pay  a flight for seats that d...\n",
       "6     yes nearly every time i fly vx this ûïear wor...\n",
       "7     really missed a prime opportunity for men with...\n",
       "8                          well i didntûbut now i do d\n",
       "9     it was amazing and arrived an hour early youre...\n",
       "10    did you know that suicide is the second leadin...\n",
       "11    i lt pretty graphics so much better than minim...\n",
       "12    this is such a great deal already thinking abo...\n",
       "13    im flying your fabulous seductive skies again ...\n",
       "14                                               thanks\n",
       "15                         sfopdx schedule is still mia\n",
       "16    so excited for my first cross country flight l...\n",
       "17    i flew from nyc to sfo last week and couldnt f...\n",
       "18                             i ü flying ÷¼üùô\n",
       "19    you know what would be amazingly awesome bosfl...\n",
       "20    why are your first fares in may over three tim...\n",
       "21                 i love this graphic httptcoutgrrwaaa\n",
       "22    i love the hipster innovation you are a feel g...\n",
       "23    will you be making bosgtlas non stop permanent...\n",
       "24    you guys messed up my seating i reserved seati...\n",
       "25    status match program i applied and its been th...\n",
       "26    what happened  ur vegan food options at least ...\n",
       "27    do you miss me dont worry well be together ver...\n",
       "28    amazing to me that we cant get any cold air fr...\n",
       "29    lax to ewr  middle seat on a red eye such a no...\n",
       "30    hi i just bked a cool birthday trip with you b...\n",
       "31    are the hours of operation for the club at sfo...\n",
       "32    help left expensive headphones on flight  iad ...\n",
       "33    awaiting my return phone call just would prefe...\n",
       "34    this is great news america could start flights...\n",
       "35    nice rt vibe with the moodlight from takeoff t...\n",
       "36    moodlighting is the only way to fly best exper...\n",
       "37         done and done best airline around hands down\n",
       "38                  when can i book my flight to hawaii\n",
       "39    your chat support is not working on your site ...\n",
       "40    view of downtown los angeles the hollywood sig...\n",
       "41    hey first time flyer next week  excited but im...\n",
       "42    plz help me win my bid upgrade for my flight  ...\n",
       "43    i have an unused ticket but moved to a new cit...\n",
       "44    are flights leaving dallas for seattle on time...\n",
       "45            im elevategold for a good reason you rock\n",
       "46               dream httptcooadrfaoq httptcolwwdackhx\n",
       "47                           wow this just blew my mind\n",
       "48    after last night tribute soundofmusic oscars i...\n",
       "49                                all were entertaining\n",
       "50    is flight  on its way was supposed to take off...\n",
       "51    julie andrews all the way though was very impr...\n",
       "52                    wish you flew out of atlanta soon\n",
       "53                             julie andrews hands down\n",
       "54    will flights be leaving dallas for la on febru...\n",
       "55    hi im so excited about your  lgagtdal deal but...\n",
       "56    you know it need it on my spotify stat guiltyp...\n",
       "57                       im lady gaga she is amazing ù÷\n",
       "58                                               carrie\n",
       "59    new marketing song httpstcoflfulcbq let us kno...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"][:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8452/288166832.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"text\"] = df[\"text\"].apply(remove_non_standard_char)\n"
     ]
    }
   ],
   "source": [
    "def remove_non_standard_char(review):\n",
    "    \"\"\"A simple function to remove characters outside the ASCII range\"\"\"\n",
    "    pattern = re.compile(r\"[^\\x00-\\x7F]+\")\n",
    "    clean_string = re.sub(pattern, \"\", review)\n",
    "    return clean_string\n",
    "\n",
    "df[\"text\"] = df[\"text\"].apply(remove_non_standard_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                             what said\n",
       "1     plus youve added commercials to the experience...\n",
       "2     i didnt today must mean i need to take another...\n",
       "3     its really aggressive to blast obnoxious enter...\n",
       "4               and its a really big bad thing about it\n",
       "5     seriously would pay  a flight for seats that d...\n",
       "6     yes nearly every time i fly vx this ear worm w...\n",
       "7     really missed a prime opportunity for men with...\n",
       "8                            well i didntbut now i do d\n",
       "9     it was amazing and arrived an hour early youre...\n",
       "10    did you know that suicide is the second leadin...\n",
       "11    i lt pretty graphics so much better than minim...\n",
       "12    this is such a great deal already thinking abo...\n",
       "13    im flying your fabulous seductive skies again ...\n",
       "14                                               thanks\n",
       "15                         sfopdx schedule is still mia\n",
       "16    so excited for my first cross country flight l...\n",
       "17    i flew from nyc to sfo last week and couldnt f...\n",
       "18                                           i  flying \n",
       "19    you know what would be amazingly awesome bosfl...\n",
       "20    why are your first fares in may over three tim...\n",
       "21                 i love this graphic httptcoutgrrwaaa\n",
       "22    i love the hipster innovation you are a feel g...\n",
       "23    will you be making bosgtlas non stop permanent...\n",
       "24    you guys messed up my seating i reserved seati...\n",
       "25    status match program i applied and its been th...\n",
       "26    what happened  ur vegan food options at least ...\n",
       "27    do you miss me dont worry well be together ver...\n",
       "28    amazing to me that we cant get any cold air fr...\n",
       "29    lax to ewr  middle seat on a red eye such a no...\n",
       "30    hi i just bked a cool birthday trip with you b...\n",
       "31    are the hours of operation for the club at sfo...\n",
       "32    help left expensive headphones on flight  iad ...\n",
       "33    awaiting my return phone call just would prefe...\n",
       "34    this is great news america could start flights...\n",
       "35    nice rt vibe with the moodlight from takeoff t...\n",
       "36    moodlighting is the only way to fly best exper...\n",
       "37         done and done best airline around hands down\n",
       "38                  when can i book my flight to hawaii\n",
       "39    your chat support is not working on your site ...\n",
       "40    view of downtown los angeles the hollywood sig...\n",
       "41    hey first time flyer next week  excited but im...\n",
       "42    plz help me win my bid upgrade for my flight  ...\n",
       "43    i have an unused ticket but moved to a new cit...\n",
       "44    are flights leaving dallas for seattle on time...\n",
       "45            im elevategold for a good reason you rock\n",
       "46               dream httptcooadrfaoq httptcolwwdackhx\n",
       "47                           wow this just blew my mind\n",
       "48    after last night tribute soundofmusic oscars i...\n",
       "49                                all were entertaining\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords_list = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_stopwords = [\"wouldn\", \"won\", \"weren\", \"wasn\", \"shouldn\", \"shan\", \"needn\", \"mustn\",\n",
    "                     \"mightn\", \"isn\", \"haven\", \"hasn\", \"hadn\", \"doesn\", \"didn\", \"couldn\",\n",
    "                     \"aren\", \"ain\", \"don\", \"not\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = list(set(stopwords_list) - set(include_stopwords)) + [\"would\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8452/618751014.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"text\"] = df[\"text\"].apply(remove_stopwords)\n"
     ]
    }
   ],
   "source": [
    "def remove_stopwords(words):\n",
    "    clean_words = []\n",
    "    for word in words.split():\n",
    "        if word not in stopwords_list:\n",
    "            clean_words.append(word)\n",
    "    return \" \".join(clean_words)\n",
    "\n",
    "df[\"text\"] = df[\"text\"].apply(remove_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                  said\n",
       "1         plus youve added commercials experience tacky\n",
       "2          didnt today must mean need take another trip\n",
       "3     really aggressive blast obnoxious entertainmen...\n",
       "4                                  really big bad thing\n",
       "5     seriously pay flight seats didnt playing reall...\n",
       "6     yes nearly every time fly vx ear worm wont go ...\n",
       "7     really missed prime opportunity men without ha...\n",
       "8                                         well didntbut\n",
       "9                 amazing arrived hour early youre good\n",
       "10    know suicide second leading cause death among ...\n",
       "11    lt pretty graphics much better minimal iconogr...\n",
       "12    great deal already thinking nd trip amp havent...\n",
       "13    im flying fabulous seductive skies u take stre...\n",
       "14                                               thanks\n",
       "15                            sfopdx schedule still mia\n",
       "16    excited first cross country flight lax mco ive...\n",
       "17    flew nyc sfo last week couldnt fully sit seat ...\n",
       "18                                               flying\n",
       "19        know amazingly awesome bosfll please want fly\n",
       "20    first fares may three times carriers seats ava...\n",
       "21                        love graphic httptcoutgrrwaaa\n",
       "22              love hipster innovation feel good brand\n",
       "23    making bosgtlas non stop permanently anytime soon\n",
       "24    guys messed seating reserved seating friends g...\n",
       "25    status match program applied three weeks calle...\n",
       "26    happened ur vegan food options least say ur si...\n",
       "27                   miss dont worry well together soon\n",
       "28    amazing cant get cold air vents vx noair worst...\n",
       "29    lax ewr middle seat red eye noob maneuver send...\n",
       "30    hi bked cool birthday trip cant add elevate ca...\n",
       "31       hours operation club sfo posted online current\n",
       "32    help left expensive headphones flight iad lax ...\n",
       "33    awaiting return phone call prefer use online s...\n",
       "34    great news america could start flights hawaii ...\n",
       "35    nice rt vibe moodlight takeoff touchdown moodl...\n",
       "36    moodlighting way fly best experience ever cool...\n",
       "37                  done done best airline around hands\n",
       "38                                   book flight hawaii\n",
       "39       chat support not working site httptcovhpgtdwpk\n",
       "40    view downtown los angeles hollywood sign beyon...\n",
       "41    hey first time flyer next week excited im hard...\n",
       "42             plz help win bid upgrade flight laxgtsea\n",
       "43    unused ticket moved new city dont fly fly expi...\n",
       "44              flights leaving dallas seattle time feb\n",
       "45                      im elevategold good reason rock\n",
       "46               dream httptcooadrfaoq httptcolwwdackhx\n",
       "47                                        wow blew mind\n",
       "48    last night tribute soundofmusic oscars think a...\n",
       "49                                         entertaining\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8452/2414733538.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"text\"] = df[\"text\"].apply(remove_one_letter_words)\n"
     ]
    }
   ],
   "source": [
    "def remove_one_letter_words(review):\n",
    "    pattern = re.compile(r\"\\b\\w\\b\")\n",
    "    clean_string = re.sub(pattern, \"\", review)\n",
    "    return clean_string\n",
    "\n",
    "df[\"text\"] = df[\"text\"].apply(remove_one_letter_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                  said\n",
       "1         plus youve added commercials experience tacky\n",
       "2          didnt today must mean need take another trip\n",
       "3     really aggressive blast obnoxious entertainmen...\n",
       "4                                  really big bad thing\n",
       "5     seriously pay flight seats didnt playing reall...\n",
       "6     yes nearly every time fly vx ear worm wont go ...\n",
       "7     really missed prime opportunity men without ha...\n",
       "8                                         well didntbut\n",
       "9                 amazing arrived hour early youre good\n",
       "10    know suicide second leading cause death among ...\n",
       "11    lt pretty graphics much better minimal iconogr...\n",
       "12    great deal already thinking nd trip amp havent...\n",
       "13    im flying fabulous seductive skies  take stres...\n",
       "14                                               thanks\n",
       "15                            sfopdx schedule still mia\n",
       "16    excited first cross country flight lax mco ive...\n",
       "17    flew nyc sfo last week couldnt fully sit seat ...\n",
       "18                                               flying\n",
       "19        know amazingly awesome bosfll please want fly\n",
       "20    first fares may three times carriers seats ava...\n",
       "21                        love graphic httptcoutgrrwaaa\n",
       "22              love hipster innovation feel good brand\n",
       "23    making bosgtlas non stop permanently anytime soon\n",
       "24    guys messed seating reserved seating friends g...\n",
       "25    status match program applied three weeks calle...\n",
       "26    happened ur vegan food options least say ur si...\n",
       "27                   miss dont worry well together soon\n",
       "28    amazing cant get cold air vents vx noair worst...\n",
       "29    lax ewr middle seat red eye noob maneuver send...\n",
       "30    hi bked cool birthday trip cant add elevate ca...\n",
       "31       hours operation club sfo posted online current\n",
       "32    help left expensive headphones flight iad lax ...\n",
       "33    awaiting return phone call prefer use online s...\n",
       "34    great news america could start flights hawaii ...\n",
       "35    nice rt vibe moodlight takeoff touchdown moodl...\n",
       "36    moodlighting way fly best experience ever cool...\n",
       "37                  done done best airline around hands\n",
       "38                                   book flight hawaii\n",
       "39       chat support not working site httptcovhpgtdwpk\n",
       "40    view downtown los angeles hollywood sign beyon...\n",
       "41    hey first time flyer next week excited im hard...\n",
       "42             plz help win bid upgrade flight laxgtsea\n",
       "43    unused ticket moved new city dont fly fly expi...\n",
       "44              flights leaving dallas seattle time feb\n",
       "45                      im elevategold good reason rock\n",
       "46               dream httptcooadrfaoq httptcolwwdackhx\n",
       "47                                        wow blew mind\n",
       "48    last night tribute soundofmusic oscars think a...\n",
       "49                                         entertaining\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/james/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "/tmp/ipykernel_8452/2807461820.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"text\"] = df[\"text\"].apply(lemmatize_words)\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "#from nltk.stem import SnowballStemmer\n",
    "nltk.download(\"wordnet\")\n",
    "#stemmer = SnowballStemmer(\"english\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_words(review):\n",
    "    lem_words = []\n",
    "    for word in review.split():\n",
    "        lem_word = lemmatizer.lemmatize(word)\n",
    "        lem_words.append(lem_word)\n",
    "    return \" \".join(lem_words)\n",
    "\n",
    "df[\"text\"] = df[\"text\"].apply(lemmatize_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk walked walk'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize_words(\"walks walked walk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                  said\n",
       "1          plus youve added commercial experience tacky\n",
       "2          didnt today must mean need take another trip\n",
       "3     really aggressive blast obnoxious entertainmen...\n",
       "4                                  really big bad thing\n",
       "5     seriously pay flight seat didnt playing really...\n",
       "6     yes nearly every time fly vx ear worm wont go ...\n",
       "7     really missed prime opportunity men without ha...\n",
       "8                                         well didntbut\n",
       "9                 amazing arrived hour early youre good\n",
       "10    know suicide second leading cause death among ...\n",
       "11    lt pretty graphic much better minimal iconography\n",
       "12    great deal already thinking nd trip amp havent...\n",
       "13    im flying fabulous seductive sky take stress a...\n",
       "14                                               thanks\n",
       "15                            sfopdx schedule still mia\n",
       "16    excited first cross country flight lax mco ive...\n",
       "17    flew nyc sfo last week couldnt fully sit seat ...\n",
       "18                                               flying\n",
       "19        know amazingly awesome bosfll please want fly\n",
       "20    first fare may three time carrier seat availab...\n",
       "21                        love graphic httptcoutgrrwaaa\n",
       "22              love hipster innovation feel good brand\n",
       "23    making bosgtlas non stop permanently anytime soon\n",
       "24    guy messed seating reserved seating friend guy...\n",
       "25    status match program applied three week called...\n",
       "26    happened ur vegan food option least say ur sit...\n",
       "27                   miss dont worry well together soon\n",
       "28    amazing cant get cold air vent vx noair worstf...\n",
       "29    lax ewr middle seat red eye noob maneuver send...\n",
       "30    hi bked cool birthday trip cant add elevate ca...\n",
       "31        hour operation club sfo posted online current\n",
       "32    help left expensive headphone flight iad lax t...\n",
       "33    awaiting return phone call prefer use online s...\n",
       "34    great news america could start flight hawaii e...\n",
       "35    nice rt vibe moodlight takeoff touchdown moodl...\n",
       "36    moodlighting way fly best experience ever cool...\n",
       "37                   done done best airline around hand\n",
       "38                                   book flight hawaii\n",
       "39       chat support not working site httptcovhpgtdwpk\n",
       "40    view downtown los angeles hollywood sign beyon...\n",
       "41    hey first time flyer next week excited im hard...\n",
       "42             plz help win bid upgrade flight laxgtsea\n",
       "43    unused ticket moved new city dont fly fly expi...\n",
       "44               flight leaving dallas seattle time feb\n",
       "45                      im elevategold good reason rock\n",
       "46               dream httptcooadrfaoq httptcolwwdackhx\n",
       "47                                        wow blew mind\n",
       "48    last night tribute soundofmusic oscar think agree\n",
       "49                                         entertaining\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/james/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impactful_words_positive(review, num_words=2):\n",
    "    \"\"\"Function that gets the most impactful positive reviews\"\"\"\n",
    "    tokens = nltk.word_tokenize(review)\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    scores = {token: sia.polarity_scores(token)[\"compound\"] for token in tokens}\n",
    "    sorted_words =  sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    impactful_words = [word for word, score in sorted_words][:num_words]\n",
    "    return \" \".join(impactful_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impactful_words_negative(review, num_words=2):\n",
    "    \"\"\"Function that gets the most impactful negative reviews\"\"\"\n",
    "    tokens = nltk.word_tokenize(review)\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    scores = {token: sia.polarity_scores(token)[\"compound\"] for token in tokens}\n",
    "    impactful_words = [(word, score) for word, score in scores.items() if score < 0]\n",
    "    sorted_words =  sorted(impactful_words, key=lambda x: np.abs(x[1]), reverse=True)\n",
    "    impactful_words = [word for word, score in sorted_words][:num_words]\n",
    "    return \" \".join(impactful_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_df = df[df['airline_sentiment']=='negative']\n",
    "pos_df = df[df['airline_sentiment']=='positive']\n",
    "neu_df = df[df['airline_sentiment']=='neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8452/876497627.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pos_df['impactful_words'] = pos_df['text'].apply(impactful_words_positive)\n",
      "/tmp/ipykernel_8452/876497627.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  neg_df['impactful_words'] = neg_df['text'].apply(impactful_words_negative)\n"
     ]
    }
   ],
   "source": [
    "pos_df['impactful_words'] = pos_df['text'].apply(impactful_words_positive)\n",
    "neg_df['impactful_words'] = neg_df['text'].apply(impactful_words_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.concat([pos_df, neg_df, neu_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.fillna(\"neutral\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment:confidence</th>\n",
       "      <th>text</th>\n",
       "      <th>impactful_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>681448153</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>plus youve added commercial experience tacky</td>\n",
       "      <td>plus youve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>681448165</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.6745</td>\n",
       "      <td>yes nearly every time fly vx ear worm wont go ...</td>\n",
       "      <td>yes nearly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>681448169</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.6559</td>\n",
       "      <td>well didntbut</td>\n",
       "      <td>well didntbut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>681448171</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>amazing arrived hour early youre good</td>\n",
       "      <td>amazing good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>681448176</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>lt pretty graphic much better minimal iconography</td>\n",
       "      <td>pretty better</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     _unit_id airline_sentiment  airline_sentiment:confidence  \\\n",
       "1   681448153          positive                        0.3486   \n",
       "6   681448165          positive                        0.6745   \n",
       "8   681448169          positive                        0.6559   \n",
       "9   681448171          positive                        1.0000   \n",
       "11  681448176          positive                        1.0000   \n",
       "\n",
       "                                                 text impactful_words  \n",
       "1        plus youve added commercial experience tacky      plus youve  \n",
       "6   yes nearly every time fly vx ear worm wont go ...      yes nearly  \n",
       "8                                       well didntbut   well didntbut  \n",
       "9               amazing arrived hour early youre good    amazing good  \n",
       "11  lt pretty graphic much better minimal iconography   pretty better  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer_sents = TfidfVectorizer(max_features=2000)\n",
    "X_sents = vectorizer_sents.fit_transform(new_df[\"text\"])\n",
    "\n",
    "vectorizer_impacts = TfidfVectorizer()\n",
    "X_impacts = vectorizer_impacts.fit_transform(new_df[\"impactful_words\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sents = pd.DataFrame(X_sents.todense())\n",
    "X_impacts = pd.DataFrame(X_impacts.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_sents, X_impacts], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = new_df[\"airline_sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9997950819672131"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_train, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1532</th>\n",
       "      <th>1533</th>\n",
       "      <th>1534</th>\n",
       "      <th>1535</th>\n",
       "      <th>1536</th>\n",
       "      <th>1537</th>\n",
       "      <th>1538</th>\n",
       "      <th>1539</th>\n",
       "      <th>1540</th>\n",
       "      <th>1541</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.681002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.572004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows × 3542 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1     2     3     4     5     6     7     8     9     ...  1532  \\\n",
       "0       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "1       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "2       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "3       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "4       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "14635   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "14636   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "14637   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "14638   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "14639   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "\n",
       "       1533  1534  1535      1536  1537  1538      1539  1540  1541  \n",
       "0       0.0   0.0   0.0  0.000000   0.0   0.0  0.681002   0.0   0.0  \n",
       "1       0.0   0.0   0.0  0.572004   0.0   0.0  0.000000   0.0   0.0  \n",
       "2       0.0   0.0   0.0  0.000000   0.0   0.0  0.000000   0.0   0.0  \n",
       "3       0.0   0.0   0.0  0.000000   0.0   0.0  0.000000   0.0   0.0  \n",
       "4       0.0   0.0   0.0  0.000000   0.0   0.0  0.000000   0.0   0.0  \n",
       "...     ...   ...   ...       ...   ...   ...       ...   ...   ...  \n",
       "14635   0.0   0.0   0.0  0.000000   0.0   0.0  0.000000   0.0   0.0  \n",
       "14636   0.0   0.0   0.0  0.000000   0.0   0.0  0.000000   0.0   0.0  \n",
       "14637   0.0   0.0   0.0  0.000000   0.0   0.0  0.000000   0.0   0.0  \n",
       "14638   0.0   0.0   0.0  0.000000   0.0   0.0  0.000000   0.0   0.0  \n",
       "14639   0.0   0.0   0.0  0.000000   0.0   0.0  0.000000   0.0   0.0  \n",
       "\n",
       "[14640 rows x 3542 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download(\"punkt\")\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.sentiment.vader import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import string\n",
    "# nltk.download(\"vader\")\n",
    "\n",
    "# sentence = \"I really enjoyed the movie. The acting was fantastic, and the plot kept me engaged throughout.\"\n",
    "# tokens = nltk.word_tokenize(sentence)\n",
    "# stopwords_ = set(stopwords.words(\"english\"))\n",
    "# filtered_tokens = [token for token in tokens if token.lower() not in stopwords_]\n",
    "# filtered_tokens = [token for token in filtered_tokens if token not in string.punctuation]\n",
    "# sa = SentimentIntensityAnalyzer()\n",
    "# scores = {token: sa.polarity_scores(token)[\"compound\"] for token in filtered_tokens}\n",
    "# sorted_words =  sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "# positive_words = [word for word, score in sorted_words if score > 0][:num_words]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f f'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "h = [\"f\", \"f\"]\n",
    "\" \".join(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>you</th>\n",
       "      <th>where</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i</td>\n",
       "      <td>[yeah, yeah]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>took</td>\n",
       "      <td>[good, bad]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    you         where\n",
       "0     i  [yeah, yeah]\n",
       "1  took   [good, bad]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.DataFrame({\"you\": [\"i\", \"took\"], \"where\": [[\"yeah\", \"yeah\"], [\"good\", \"bad\"]]})\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"where\"] = d[\"where\"].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>you</th>\n",
       "      <th>where</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i</td>\n",
       "      <td>yeah yeah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>took</td>\n",
       "      <td>good bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    you      where\n",
       "0     i  yeah yeah\n",
       "1  took   good bad"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
